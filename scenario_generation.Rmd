#Scenario Generation

## Setting R code chunk options

First R code chunk is used for setting the options for all R code chunks.
The choice echo=TRUE means both code and output will appear on report, include = FALSE neither code nor output is printed.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,tidy.opts=list(width.cutoff=80), tidy=FALSE) 
```

## Loading packages and initializing

Second R code chunk is for loading packages.
By setting message = FALSE and warning = FALSE, the code will appear but it will node include messages and warnings.

```{r package, message=FALSE, warning=FALSE}
library(lubridate)
library(ggplot2)
library(forecast)  
library(Kendall)
library(tseries)
library(outliers)
library(tidyverse)
library(smooth)
library(zoo)
library(kableExtra)
```

## Cholesky decomposition in R (Notes)

Notes from class:

Suppose w (Noe have 3 variables that follow a $N(0,1)$ distribution and are highly correlated. We want to make sure that when we generate scenarios, i.e. draws from the normal distribution, for all three variable we take their correlation into account. In other words if they are highly positively correlated, higher values for one leads to higher values for the other two. 

Project step: generating scenarios for all of our predictor variables (temperature, coal and lignite, hydro, natural gas, nuclear, solar, wind)

```{r}

nvar=7
nscen=1000

#Generate 1000 normal random variates for each of the 7 predictor variables
X=array(0,c(nvar,nscen))
for(i in 1:nvar){
  X[i,]=rnorm(nscen,mean=0,sd=1)   
}
```

The 1000 normal variate were independently generated, so if we calculate the correlation we will not find a significant correlation among the three variables.

```{r}
#Calculating correlation matrix R
#finding correlation among three values (values should be close to 0)
Xcor=cor(t(X))  

# Note: the t(X) will return the transpose of matrix X. 
# We need to transpose so that cor() function finds the correlations
# among the three variable and not among the 1000 scenarios

print(Xcor)
```

From historical data, calculating the correlation among the seven variables, then storing the correlation on a correlation matrix R.

```{r}
#Getting correlation matrix from historical data.

#Need to create one dataframe with all the columns of the predictor variables of interest

# keeping time stamp and Average temp from ERCOT_temp

# Keeping time stamp and fuel mix columns
fuel_mix_sub <- ERCOT_fuelmix[ , c("Date", "coal_and_lignite", "hydro", "nuclear", "solar", "wind", "natural_gas")]

merged_df <- merge(ERCOT_temp_daily, fuel_mix_sub, by = "Date", all = TRUE)

#Finding correlation matrix, excluding date column
R <- cor(merged_df[ , -1], use = "complete.obs")

print(R)
```


We want our draws to account for that correlation, o.w., we may be generating scenarios that are not realistic. We will pass this correlation matrix R through our generated scenarios X using Cholesky decomposition.


```{r}
# Get Cholesky decomposition, chol() will give upper triangular matrix
U=chol(R)
print(U)

# Transpose U to get lower triangular matrix just 
L=t(U) 
print(L)
```
Any matrix can be decomposed into two other matrix, and this is how we can decompose R to upper and lower triangular matrix.

This lower triangular matrix (3x3) will be multiplied by our scenarios matrix X (7x1000) and will lead to new 1000 scenarios.

```{r}
#Passing the correlation matrix R to the scenarios in matrix X

Y=L%*%X   # the symbol %*% is for matrix multiplication 

# Checking if the correlation of generated scenarios matches matrix R
Ycor=cor(t(Y))  
print(Ycor) #compare Ycor with R and you will see it worked.
#you create correlation between variables by manipulating draws of other variables (note row one same between Y and X, different for bottom two rows)
```
Essentially trying to represent real life relationships in randomly drawn values for variables. --> guaranteeing your scenarios are correlated and represent what could happen in real life

#Ignore this! Old work

## Generating scenarios with ARIMA model (I also did it without the MSTS object, so may have to update)

Now let's consider a real world applications of scenario generation based on the ARIMA model.

```{r}
#transforming into normal distribution as we create the ts object
ts_load_transformed <- ts(log(ERCOT_load$load), frequency = 12, 
                start = c(2017,1,1))

autoplot(ts_load_transformed)
autoplot(ts_load)
#the data does not follow normal distribution, which is why we are taking the log of the data!
#Check this one with team! It's def not normally distributed, but log transformation doesn't seem like it does much?
```

```{r}
# Create Fourier terms (K = 2 harmonics)
xreg_hist <- merged_df[ , -1]  # Remove Date column

K <- 2
fourier_terms <- fourier(ts_load_transformed, K = K)
xreg_full <- cbind(fourier_terms, xreg_hist)

# Fit ARIMA + Fourier model with exogenous variables
fit_arima_fourier <- auto.arima(ts_load_transformed, xreg = as.matrix(xreg_full))

# Forecast horizon and number of scenarios
horizon <- 12
nscen <- 10

#Reshaping Y [horizon x nvar x nscen] to align with monthly steps
nvar <- 7
Y <- array(Y, dim = c(nvar, horizon, nscen))  # reshaped if needed

# Generate Fourier terms for forecast horizon
future_fourier <- fourier(ts_load_transformed, K = K, h = horizon)

# Array for storing load scenarios
load_scenarios <- matrix(0, nrow = horizon, ncol = nscen)

# Generating load scenarios using future Fourier + predictor simulations
for (s in 1:nscen) {
  # Extract simulated predictor values for this scenario
  predictors_sim <- t(Y[ , , s])  # [12 x 7]
  
  # Combine Fourier + predictors
  xreg_future <- cbind(future_fourier, predictors_sim)
  
  #Make sure column names match training set
  colnames(xreg_future) <- colnames(xreg_full)
  
  # Forecast load using model
  forecast_result <- forecast(fit_arima_fourier, xreg = xreg_future, h = horizon)
  
  # Manually compute forecast std dev
  load_sd <- (forecast_result$upper[ , 1] - forecast_result$lower[ , 1]) / 
             (2 * qnorm(0.5 + forecast_result$level[1] / 200))
  
  # Generate stochastic scenario
  load_scenarios[ , s] <- rnorm(horizon, mean = forecast_result$mean, sd = load_sd)
}

# Back-transform from log to actual load
load_scenarios_exp <- exp(load_scenarios)
```

Generate ARIMA + Fourier model for load, and now we're generating scenarios.

I want to calculate all possible scenarios and optimize over those!

Note that the correlation is closer to the sample correlation matrix R.
Just to illustrate what we have done let's plot the scenarios that we generated

```{r}
# Set y-axis range
ymin <- min(load_scenarios_exp)
ymax <- max(load_scenarios_exp)

# Plot the first scenario
plot(load_scenarios_exp[ , 1], type = "l", col = "gray", ylim = c(ymin, ymax),
     xlab = "Month", ylab = "Load (MW)", main = "ERCOT Load Scenarios (ARIMA + Fourier)")

# Add rest of the scenarios
for (s in 2:nscen) {
  lines(load_scenarios_exp[ , s], col = "gray")
}

# Add the point forecast (mean of each month across all scenarios)
lines(rowMeans(load_scenarios_exp), col = "blue", lwd = 2)

legend("topright", legend = c("Forecast Mean", "Scenarios"), col = c("blue", "gray"), lty = 1, lwd = c(2, 1))

```
This is a representation of what the 1 year/12 months ahead that we are generating. 



#Ignore this! Old work
##Doing it without transforming load (because values look weird in the transformed load) (I also did it without the msts object, so will update)
```{r}
# Create Fourier terms (K = 2 harmonics)
xreg_hist <- merged_df[ , -1]  # Remove Date column

ts_load_2 <- ts(log(ERCOT_load$load), frequency = 12, start = c(2017, 1))

K <- 2
fourier_terms <- fourier(ts_load_2, K = K)
xreg_full <- cbind(fourier_terms, xreg_hist)

# Fit ARIMA + Fourier model with exogenous variables
fit_arima_fourier <- auto.arima(ts_load_2, xreg = as.matrix(xreg_full))

# Forecast horizon and number of scenarios
horizon <- 12
nscen <- 10

#Reshaping Y [horizon x nvar x nscen] to align with monthly steps
nvar <- 7
Y <- array(Y, dim = c(nvar, horizon, nscen))  # reshaped if needed

# Generate Fourier terms for forecast horizon
future_fourier <- fourier(ts_load_2, K = K, h = horizon)

# Array for storing load scenarios
load_scenarios <- matrix(0, nrow = horizon, ncol = nscen)

# Generating load scenarios using future Fourier + predictor simulations
for (s in 1:nscen) {
  # Extract simulated predictor values for this scenario
  predictors_sim <- t(Y[ , , s])  # [12 x 7]
  
  # Combine Fourier + predictors
  xreg_future <- cbind(future_fourier, predictors_sim)
  
  #Make sure column names match training set
  colnames(xreg_future) <- colnames(xreg_full)
  
  # Forecast load using model
  forecast_result <- forecast(fit_arima_fourier, xreg = xreg_future, h = horizon)
  
  # Manually compute forecast std dev
  load_sd <- (forecast_result$upper[ , 1] - forecast_result$lower[ , 1]) / 
             (2 * qnorm(0.5 + forecast_result$level[1] / 200))
  
  # Generate stochastic scenario
  load_scenarios[ , s] <- rnorm(horizon, mean = forecast_result$mean, sd = load_sd)
}

```

Generate ARIMA + Fourier model for load, and now we're generating scenarios.

I want to calculate all possible scenarios and optimize over those!

Note that the correlation is closer to the sample correlation matrix R.
Just to illustrate what we have done let's plot the scenarios that we generated

```{r}
# Set y-axis range
ymin <- min(load_scenarios)
ymax <- max(load_scenarios)

# Plot the first scenario
plot(load_scenarios[ , 1], type = "l", col = "gray", ylim = c(ymin, ymax),
     xlab = "Month", ylab = "Load (MW)", main = "ERCOT Load Scenarios (ARIMA + Fourier)")

# Add rest of the scenarios
for (s in 2:nscen) {
  lines(load_scenarios[ , s], col = "gray")
}

# Add the point forecast (mean of each month across all scenarios)
lines(rowMeans(load_scenarios), col = "blue", lwd = 2)

legend("topright", legend = c("Forecast Mean", "Scenarios"), col = c("blue", "gray"), lty = 1, lwd = c(2, 1))

```



#Final scenario generation model

##Train/test version

Need to remove last 365 from the temperature/fuel mix stuff

use only load_train
do the scenarios for the next 365 days (and compare with the load_test data)

```{r}
merged_df_train <- merged_df[1:(nrow(merged_df) - 365), ]

#Finding correlation matrix, excluding date column
R <- cor(merged_df_train[ , -1], use = "complete.obs")

print(R)
```

We want our draws to account for that correlation, o.w., we may be generating scenarios that are not realistic. We will pass this correlation matrix R through our generated scenarios X using Cholesky decomposition.


```{r}
# Get Cholesky decomposition, chol() will give upper triangular matrix
U=chol(R)
print(U)

# Transpose U to get lower triangular matrix just 
L=t(U) 
print(L)
```
Any matrix can be decomposed into two other matrix, and this is how we can decompose R to upper and lower triangular matrix.

This lower triangular matrix (3x3) will be multiplied by our scenarios matrix X (7x1000) and will lead to new 1000 scenarios.

```{r}
#Passing the correlation matrix R to the scenarios in matrix X

Y=L%*%X   # the symbol %*% is for matrix multiplication 

# Checking if the correlation of generated scenarios matches matrix R
Ycor=cor(t(Y))  
print(Ycor) #compare Ycor with R and you will see it worked.
#you create correlation between variables by manipulating draws of other variables (note row one same between Y and X, different for bottom two rows)
```
Essentially trying to represent real life relationships in randomly drawn values for variables. --> guaranteeing your scenarios are correlated and represent what could happen in real life

## Generating scenarios with ARIMA + Fourier model

```{r}
#This was working weirdly with the msts object, so recreating ts_objects to work with here
ts_load <-ts(ERCOT_load$load, frequency = 365, start = c(2017, 1))

n_for <-  365

ts_load_train <- subset(ts_load,end = length(ts_load)-n_for) #stops 365 days before

#create a subset for testing purpose
ts_load_test <- subset(ts_load, start = length(ts_load)-n_for) #last 365 observations

autoplot(ts_load_train)
autoplot(ts_load_test)

```

```{r}
# Create Fourier terms (K = 2 harmonics)
xreg_hist <- merged_df_train[ , -1]  # Remove Date column

# Step 2: Generate Fourier terms (K must match seasonal.periods length)
K <- 2  # 2 harmonics for weekly, 8 for annual
fourier_terms <- fourier(ts_load_train, K = K)

# Step 3: Combine Fourier + exogenous regressors
xreg_hist <- merged_df_train[ , -1]  # Drop Date column
xreg_full <- cbind(fourier_terms, xreg_hist)

# Step 4: Fit ARIMA on raw load with Fourier + xregs
fit_arima_fourier <- auto.arima(ts_load_train, 
                                 seasonal = FALSE, 
                                 xreg = as.matrix(xreg_full))

# Step 5: Forecast setup
horizon <- 365
nscen <- 10
nvar <- 7  # number of exogenous predictors

# Step 6: Generate future Fourier terms
future_fourier <- fourier(ts_load_train, K = K, h = horizon)

# Step 7: Simulated predictor array (already created)
#Reshaping Y [horizon x nvar x nscen] to align with monthly steps
Y <- array(Y, dim = c(nvar, horizon, nscen))  # reshaped if needed
load_scenarios <- matrix(0, nrow = horizon, ncol = nscen)

# Step 8: Forecast loop
for (s in 1:nscen) {
  # Ensure simulated predictors have correct orientation
  predictors_sim <- t(Y[ , , s])  # [horizon x nvar]
  
  # Combine Fourier + predictors
  xreg_future <- cbind(future_fourier, predictors_sim)
  
  # Match column names
  colnames(xreg_future) <- colnames(xreg_full)
  
  # Forecast using fitted model
  forecast_result <- forecast(fit_arima_fourier, xreg = xreg_future, h = horizon)
  
  # Estimate SD from forecast intervals
  load_sd <- (forecast_result$upper[, 1] - forecast_result$lower[, 1]) / 
             (2 * qnorm(0.5 + forecast_result$level[1] / 200))
  
  # Generate scenario (raw scale — can go negative unless handled)
  load_scenarios[ , s] <- pmax(
    rnorm(horizon, mean = forecast_result$mean, sd = load_sd)
  )
}

```

Generate ARIMA + Fourier model for load, and now we're generating scenarios.

I want to calculate all possible scenarios and optimize over those!

```{r}

# Set y-axis range
ymin <- min(load_scenarios, na.rm = TRUE)
ymax <- max(load_scenarios, na.rm = TRUE)

with(list(), {
  matplot(load_scenarios, type = "l", lty = 1, col = "gray", ylim = c(ymin, ymax),
          xlab = "Day", ylab = "Load (MW)", main = "ERCOT Load Scenarios (ARIMA + Fourier)")
  lines(rowMeans(load_scenarios), col = "blue", lwd = 2)
  lines(as.numeric(ts_load_test), col = "red", lwd = 2, lty = 2)
  legend("topright",
         legend = c("Forecast Mean", "Scenarios", "Actual Load (Test)"),
         col = c("blue", "gray", "red"),
         lty = c(1, 1, 2),
         lwd = c(2, 1, 2))
})

```
This is a representation of the 365 days we are generating. 

```{r}
# Set y-axis range
ymin <- min(load_scenarios, na.rm = TRUE)
ymax <- max(load_scenarios, na.rm = TRUE)

with(list(), {
  matplot(load_scenarios, type = "l", lty = 1, col = "gray", ylim = c(ymin, ymax),
          xlab = "Day", ylab = "Load (MW)", main = "ERCOT Load Scenarios (ARIMA + Fourier)")
  lines(rowMeans(load_scenarios), col = "blue", lwd = 2)
  legend("topright",
         legend = c("Forecast Mean", "Scenarios"),
         col = c("blue", "gray"),
         lty = c(1, 1),
         lwd = c(2, 1))
})
```

